{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# MIMIC_Sepsis\n",
            "\n",
            "## 1. Preparation\n",
            "\n",
            "To run this document the following requirements must be satisfied:\n",
            "\n",
            "- Implement the database mimic in **PostgreSQL** and start it. The instruction can be seen [here](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iv/buildmimic/postgres). (The name of this environment should be **mimiciv**)\n",
            "- generate useful abstractions of raw MIMIC-IV data. The instruction be seen [here](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iv/concepts_postgres) \n",
            "\n",
            "\n",
            "\n",
            "To install all the libraries, run:\n",
            "```\n",
            "pip install psycopg2 csv pandas\n",
            "```\n",
            "\n",
            "\n",
            "After all the preparation is done, run the following cell to set the connection to the database.\n",
            " "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import psycopg2\n",
            "from psycopg2 import sql\n",
            "import csv\n",
            "import pandas as pd\n",
            "import os\n",
            "\n",
            "# implement the username, password and database name\n",
            "conn = psycopg2.connect(host='', user='', password='', database='mimiciv')"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 2. Extract selected data from the original database \n",
            "\n",
            "According to the paper we need to extract the **state space** and **action space** respectively from the mimiciv database. The table **mimic4 itemid.csv** lists all the items required.\n",
            "\n",
            "* Here the *IV fluid bolus* of the action space is removed as no data could be found.\n",
            "\n",
            "#### **Uncomment the following line if you first time run the code**"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "# uncomment the following line if you first time run the code\n",
            "\n",
            "# # Read the SQL file\n",
            "\n",
            "# try:\n",
            "#     with open('sql_file/selection_patients_cohort.sql', 'r') as file0:\n",
            "#         sql_script_selection_patients_cohort = file0.read()\n",
            "\n",
            "#     with open('sql_file/action_from_inputevents.sql', 'r') as file1:\n",
            "#         sql_script_action = file1.read()\n",
            "        \n",
            "#     with open('sql_file/chartevents_dataneeded.sql', 'r') as file2:\n",
            "#         sql_script_state = file2.read()\n",
            "\n",
            "#     # Execute the SQL script\n",
            "#     cursor = conn.cursor()\n",
            "    \n",
            "#     cursor.execute(sql.SQL(sql_script_selection_patients_cohort))\n",
            "#     cursor.execute(sql.SQL(sql_script_action))\n",
            "#     cursor.execute(sql.SQL(sql_script_state))\n",
            "\n",
            "#     conn.commit()\n",
            "#     cursor.close()\n",
            "    \n",
            "    \n",
            "# except (Exception, psycopg2.DatabaseError) as error:\n",
            "#     print(\"Error executing SQL statement:\", error)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Number of stay_ids: 6669\n"
               ]
            }
         ],
         "source": [
            "with conn.cursor() as cursor:\n",
            "    command = \"SELECT distinct stay_id FROM mimiciv_derived.sepsis_patients_cohort ;\"\n",
            "    cursor.execute(command)   \n",
            "    result = cursor.fetchall()\n",
            "    stay_ids= [row[0] for row in result]\n",
            "    num_stay_ids = len(stay_ids)\n",
            "    print('Number of stay_ids: ' + str(num_stay_ids))\n",
            "    cursor.close()"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 3. Data transfor\n",
            "Here we first deal with the action data. \n",
            "TODO: here the value per minute is computed, do we need this? (paper4.1,P5)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "output:Norepinephrine.csv\n",
                  "output:Vasopressin.csv\n",
                  "output:Dobutamine.csv\n",
                  "output:Milrinone.csv\n",
                  "output:Phenylephrine.csv\n"
               ]
            }
         ],
         "source": [
            "# generate the dictionary of action\n",
            "with open('csv/itemid_label_action.csv', newline='') as csvfile:\n",
            "    # Create a CSV reader object\n",
            "    reader = csv.reader(csvfile)\n",
            "    # Skip the header row\n",
            "    next(reader)\n",
            "    # Initialize an empty dictionary and list\n",
            "    action_label = {}\n",
            "    a_itemid_list = []\n",
            "    # Iterate over the rows in the CSV file\n",
            "    for row in reader:\n",
            "        # Add the key-value pair to the dictionary\n",
            "        action_label[row[0]] = row[1]\n",
            "        # Add the itemid to the list\n",
            "        a_itemid_list.append(row[0])\n",
            "\n",
            "with conn.cursor() as cursor:\n",
            "\n",
            "    for itemid in a_itemid_list:\n",
            "        command = \"select stay_id, starttime, endtime,amount from mimiciv_derived.sepsis_action where itemid={} order by starttime;\".format(itemid)\n",
            "        cursor.execute(command)\n",
            "\n",
            "        result = cursor.fetchall()\n",
            "        df = pd.DataFrame(result)\n",
            "        df.columns = ['stay_id', 'starttime', 'endtime', 'amount']\n",
            "        \n",
            "        df['duration'] = df['endtime'] - df['starttime']\n",
            "        df['duration'] = df['duration'].dt.total_seconds()  # Convert duration to seconds\n",
            "        df['duration'] = df['duration'] / 60\n",
            "        df['value_per_minute'] = df['amount'] / df['duration']\n",
            "        \n",
            "        os.makedirs('./output/action', exist_ok=True)\n",
            "        df.to_csv('./output/action/{}.csv'.format(action_label[str(itemid)]), index=0)\n",
            "        print(\"output:\"+action_label[str(itemid)]+\".csv\")\n",
            "    cursor.close()"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Then, we treat the **state space** with similar method."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "output:Heartrate.csv                           \tnumber of stay_id:6669\n",
                  "drop:ABPs.csv                                \tnumber of stay_id:2129\n",
                  "output:NBPs.csv                                \tnumber of stay_id:6632\n",
                  "drop:ABPd.csv                                \tnumber of stay_id:2131\n",
                  "output:NBPd.csv                                \tnumber of stay_id:6632\n",
                  "drop:ABPm.csv                                \tnumber of stay_id:2168\n",
                  "output:NBPm.csv                                \tnumber of stay_id:6632\n",
                  "output:RespiratoryRate.csv                     \tnumber of stay_id:6669\n",
                  "output:TemperatureF.csv                        \tnumber of stay_id:6576\n",
                  "drop:TemperatureC.csv                        \tnumber of stay_id:832\n",
                  "output:PH_A.csv                                \tnumber of stay_id:3663\n",
                  "output:PH_V.csv                                \tnumber of stay_id:3184\n",
                  "output:ABE.csv                                 \tnumber of stay_id:3645\n",
                  "output:Hematocrit_serum.csv                    \tnumber of stay_id:6596\n",
                  "drop:Hematocrit_wholeblood.csv               \tnumber of stay_id:1200\n",
                  "output:Hemoglobin.csv                          \tnumber of stay_id:6591\n",
                  "output:Platele.csv                             \tnumber of stay_id:6591\n",
                  "output:WBC.csv                                 \tnumber of stay_id:6593\n",
                  "output:Chloride_serum.csv                      \tnumber of stay_id:6618\n",
                  "drop:Chloride_wholeblood.csv                 \tnumber of stay_id:1058\n",
                  "output:Calcium_ion.csv                         \tnumber of stay_id:3459\n",
                  "output:Calcium_nonion.csv                      \tnumber of stay_id:6549\n",
                  "output:Potassium_serum.csv                     \tnumber of stay_id:6617\n",
                  "drop:Potassium_wholeblood.csv                \tnumber of stay_id:2181\n",
                  "output:Sodium_serum.csv                        \tnumber of stay_id:6617\n",
                  "drop:Sodium_wholeblood.csv                   \tnumber of stay_id:1401\n",
                  "output:ProthrombinTime.csv                     \tnumber of stay_id:6011\n",
                  "output:PTT.csv                                 \tnumber of stay_id:5970\n",
                  "output:INR.csv                                 \tnumber of stay_id:6011\n",
                  "drop:SaO2.csv                                \tnumber of stay_id:1905\n",
                  "output:SpO2.csv                                \tnumber of stay_id:6665\n",
                  "Error executing SQL statement: Length mismatch: Expected axis has 0 elements, new values have 3 elements\n",
                  "drop:PaO2.csv                                \tnumber of stay_id:0\n",
                  "output:PaCO2.csv                               \tnumber of stay_id:3645\n",
                  "output:FiO2.csv                                \tnumber of stay_id:4044\n",
                  "output:BUN.csv                                 \tnumber of stay_id:6616\n",
                  "output:Creatinine_serum.csv                    \tnumber of stay_id:6618\n",
                  "drop:Creatinine_wholeblood.csv               \tnumber of stay_id:40\n",
                  "output:Albumin.csv                             \tnumber of stay_id:3608\n",
                  "output:AnionGap.csv                            \tnumber of stay_id:6617\n",
                  "output:TotalBilirubin.csv                      \tnumber of stay_id:4797\n",
                  "drop:DirectBilirubin.csv                     \tnumber of stay_id:818\n",
                  "output:ALT.csv                                 \tnumber of stay_id:4771\n",
                  "output:AST.csv                                 \tnumber of stay_id:4769\n",
                  "drop:UrineOutput.csv                         \tnumber of stay_id:1\n",
                  "output:GCS_EyeOpening.csv                      \tnumber of stay_id:6669\n",
                  "output:GCS_VerbalResponse.csv                  \tnumber of stay_id:6668\n",
                  "output:GCS_MotorResponse.csv                   \tnumber of stay_id:6668\n"
               ]
            }
         ],
         "source": [
            "# generate the dictionary of itemid-abbr\n",
            "with open('csv/itemid_label_state.csv', newline='') as csvfile:\n",
            "    # Create a CSV reader object\n",
            "    reader = csv.reader(csvfile)\n",
            "    # Skip the header row\n",
            "    next(reader)\n",
            "    # Initialize an empty dictionary and list\n",
            "    label = {}\n",
            "    itemid_list = []\n",
            "    # Iterate over the rows in the CSV file\n",
            "    for row in reader:\n",
            "        # Add the key-value pair to the dictionary\n",
            "        label[row[0]] = row[1]\n",
            "        # Add the itemid to the list\n",
            "        itemid_list.append(row[0])\n",
            "\n",
            "# Execute the SQL command\n",
            "with conn.cursor() as cursor:\n",
            "    \n",
            "    for itemid in itemid_list:\n",
            "        \n",
            "        command_count = \"select count(distinct(stay_id)) from mimiciv_derived.sepsis_state where itemid={};\".format(itemid)\n",
            "        cursor.execute(command_count)\n",
            "        num = cursor.fetchone()[0]\n",
            "        \n",
            "        command = \"select stay_id, charttime, valuenum from mimiciv_derived.sepsis_state where itemid={} order by charttime;\".format(itemid)\n",
            "        cursor.execute(command)   \n",
            "        result = cursor.fetchall()\n",
            "        df=pd.DataFrame(result)\n",
            "        try:\n",
            "            df.columns = ['stay_id', 'charttime', 'valuenum']\n",
            "        except (Exception, psycopg2.DatabaseError) as error:\n",
            "            print(\"Error executing SQL statement:\", error) \n",
            "        os.makedirs('./output/state', exist_ok=True)\n",
            "        \n",
            "        if (num<num_stay_ids/3):\n",
            "            print(\"drop:{0:40}\".format(label[str(itemid)]+\".csv\")+\"\\tnumber of stay_id:\"+str(num))\n",
            "        else:\n",
            "            df.to_csv('./output/state/{}.csv'.format(label[str(itemid)]),index=0)\n",
            "            print(\"output:{0:40}\".format(label[str(itemid)]+\".csv\")+\"\\tnumber of stay_id:\"+str(num))\n",
            "        \n",
            "    cursor.close()"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 4.hourly sample"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/tmp/ipykernel_13898/2545290030.py:18: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv(path,names=['stay_id', 'chartdatetime', feature,feature_num ])\n",
                  "/tmp/ipykernel_13898/2545290030.py:25: SettingWithCopyWarning: \n",
                  "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                  "Try using .loc[row_indexer,col_indexer] = value instead\n",
                  "\n",
                  "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                  "  df_filtered['chartdatetime'] = pd.to_datetime(df_filtered['chartdatetime'])\n",
                  "/tmp/ipykernel_13898/2545290030.py:18: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv(path,names=['stay_id', 'chartdatetime', feature,feature_num ])\n",
                  "/tmp/ipykernel_13898/2545290030.py:25: SettingWithCopyWarning: \n",
                  "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                  "Try using .loc[row_indexer,col_indexer] = value instead\n",
                  "\n",
                  "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                  "  df_filtered['chartdatetime'] = pd.to_datetime(df_filtered['chartdatetime'])\n",
                  "/tmp/ipykernel_13898/2545290030.py:18: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv(path,names=['stay_id', 'chartdatetime', feature,feature_num ])\n",
                  "/tmp/ipykernel_13898/2545290030.py:25: SettingWithCopyWarning: \n",
                  "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                  "Try using .loc[row_indexer,col_indexer] = value instead\n",
                  "\n",
                  "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                  "  df_filtered['chartdatetime'] = pd.to_datetime(df_filtered['chartdatetime'])\n",
                  "/tmp/ipykernel_13898/2545290030.py:18: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv(path,names=['stay_id', 'chartdatetime', feature,feature_num ])\n",
                  "/tmp/ipykernel_13898/2545290030.py:25: SettingWithCopyWarning: \n",
                  "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                  "Try using .loc[row_indexer,col_indexer] = value instead\n",
                  "\n",
                  "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                  "  df_filtered['chartdatetime'] = pd.to_datetime(df_filtered['chartdatetime'])\n",
                  "/tmp/ipykernel_13898/2545290030.py:18: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv(path,names=['stay_id', 'chartdatetime', feature,feature_num ])\n",
                  "/tmp/ipykernel_13898/2545290030.py:25: SettingWithCopyWarning: \n",
                  "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                  "Try using .loc[row_indexer,col_indexer] = value instead\n",
                  "\n",
                  "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                  "  df_filtered['chartdatetime'] = pd.to_datetime(df_filtered['chartdatetime'])\n",
                  "/tmp/ipykernel_13898/2545290030.py:18: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv(path,names=['stay_id', 'chartdatetime', feature,feature_num ])\n",
                  "/tmp/ipykernel_13898/2545290030.py:25: SettingWithCopyWarning: \n",
                  "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                  "Try using .loc[row_indexer,col_indexer] = value instead\n",
                  "\n",
                  "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                  "  df_filtered['chartdatetime'] = pd.to_datetime(df_filtered['chartdatetime'])\n",
                  "/tmp/ipykernel_13898/2545290030.py:18: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv(path,names=['stay_id', 'chartdatetime', feature,feature_num ])\n",
                  "/tmp/ipykernel_13898/2545290030.py:25: SettingWithCopyWarning: \n",
                  "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                  "Try using .loc[row_indexer,col_indexer] = value instead\n",
                  "\n",
                  "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                  "  df_filtered['chartdatetime'] = pd.to_datetime(df_filtered['chartdatetime'])\n",
                  "/tmp/ipykernel_13898/2545290030.py:18: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv(path,names=['stay_id', 'chartdatetime', feature,feature_num ])\n",
                  "/tmp/ipykernel_13898/2545290030.py:25: SettingWithCopyWarning: \n",
                  "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                  "Try using .loc[row_indexer,col_indexer] = value instead\n",
                  "\n",
                  "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                  "  df_filtered['chartdatetime'] = pd.to_datetime(df_filtered['chartdatetime'])\n",
                  "/tmp/ipykernel_13898/2545290030.py:18: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv(path,names=['stay_id', 'chartdatetime', feature,feature_num ])\n",
                  "/tmp/ipykernel_13898/2545290030.py:25: SettingWithCopyWarning: \n",
                  "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                  "Try using .loc[row_indexer,col_indexer] = value instead\n",
                  "\n",
                  "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                  "  df_filtered['chartdatetime'] = pd.to_datetime(df_filtered['chartdatetime'])\n"
               ]
            }
         ],
         "source": [
            "# Set the folder path where the CSV files are stored\n",
            "folder_path = './output/state/'\n",
            "columns=['chartdatetime']\n",
            "\n",
            "# define a new dataframe\n",
            "df_output = pd.DataFrame(columns=columns)\n",
            "\n",
            "#FIXME flag only for test\n",
            "i=0\n",
            "\n",
            "# Loop through the file paths and read each file into a DataFrame\n",
            "for itemid in itemid_list:\n",
            "    \n",
            "    feature=label[str(itemid)]\n",
            "    feature_num=feature+'num'\n",
            "    path = folder_path + feature+'.csv'\n",
            "    # Load the CSV file into a pandas DataFrame\n",
            "    df = pd.read_csv(path,names=['stay_id', 'chartdatetime', feature,feature_num ])\n",
            "\n",
            "    # selected_id = 32768012\n",
            "    selected_id = 32950566\n",
            "    df_filtered = df[df['stay_id'] == selected_id]\n",
            "    \n",
            "    # Convert the 'datetime' column to a datetime object\n",
            "    df_filtered['chartdatetime'] = pd.to_datetime(df_filtered['chartdatetime'])\n",
            "\n",
            "    # Set the 'datetime' column as the DataFrame's index\n",
            "    df_filtered.set_index('chartdatetime', inplace=True)\n",
            "\n",
            "    # # Resample the DataFrame hourly and forward fill missing values\n",
            "    df_hourly= df_filtered.resample('H').ffill()\n",
            "    df_hourly=df_hourly.drop(['stay_id'],axis=1)\n",
            "    #print(df_hourly)\n",
            "    df_output=pd.merge(df_output,df_hourly,how='outer',on='chartdatetime')\n",
            "    \n",
            "    i+=1\n",
            "    if(i==30): break\n",
            "\n",
            "os.makedirs('./output/hourly_sample/', exist_ok=True)\n",
            "df_output.to_csv(f'./output/hourly_sample/stay_id{selected_id}.csv',index=0)\n",
            "\n",
            "# # Reset the index and save the resampled DataFrame to a new CSV file\n",
            "# df_hourly.reset_index().to_csv('./output/your_resampled_file.csv', index=False, header=None)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "MLhomework",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.11"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
