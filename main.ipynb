{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# MIMIC_Sepsis\n",
            "\n",
            "## 1. Preparation\n",
            "\n",
            "To run this document the following requirements must be satisfied:\n",
            "\n",
            "- Implement the database mimic in **PostgreSQL** and start it. The instruction can be seen [here](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iv/buildmimic/postgres). (The name of this environment should be **mimiciv**)\n",
            "- generate useful abstractions of raw MIMIC-IV data. The instruction be seen [here](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iv/concepts_postgres) \n",
            "\n",
            "\n",
            "\n",
            "To install all the libraries, run:\n",
            "```\n",
            "pip install psycopg2 csv pandas\n",
            "```\n",
            "\n",
            "\n",
            "After all the preparation is done, run the following cell to set the connection to the database.\n",
            " "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import psycopg2\n",
            "from psycopg2 import sql\n",
            "import csv\n",
            "import pandas as pd\n",
            "import os\n",
            "import shutil\n",
            "import csv\n",
            "\n",
            "# implement the username, password and database name\n",
            "conn = psycopg2.connect(host='', user='', password='', database='mimiciv')"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 2. Extract selected data from the original database \n",
            "\n",
            "According to the paper we need to extract the **state space** and **action space** respectively from the mimiciv database. The table **mimic4 itemid.csv** lists all the items required.\n",
            "\n",
            "* Here the *IV fluid bolus* of the action space is removed as no data could be found.\n",
            "\n",
            "#### **Uncomment the following line if you first time run the code**"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "# uncomment the following line if you first time run the code\n",
            "\n",
            "# Read the SQL file\n",
            "\n",
            "try:\n",
            "    with open('sql_file/selection_patients_cohort.sql', 'r') as file0:\n",
            "        sql_script_selection_patients_cohort = file0.read()\n",
            "\n",
            "    with open('sql_file/action_from_inputevents.sql', 'r') as file1:\n",
            "        sql_script_action = file1.read()\n",
            "        \n",
            "    with open('sql_file/chartevents_dataneeded.sql', 'r') as file2:\n",
            "        sql_script_state = file2.read()\n",
            "\n",
            "    # Execute the SQL script\n",
            "    cursor = conn.cursor()\n",
            "    \n",
            "    # cursor.execute(sql.SQL(sql_script_selection_patients_cohort))\n",
            "    cursor.execute(sql.SQL(sql_script_action))\n",
            "    # cursor.execute(sql.SQL(sql_script_state))\n",
            "\n",
            "    conn.commit()\n",
            "    cursor.close()\n",
            "    \n",
            "    \n",
            "except (Exception, psycopg2.DatabaseError) as error:\n",
            "    print(\"Error executing SQL statement:\", error)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Number of stay_ids: 6669\n"
               ]
            }
         ],
         "source": [
            "with conn.cursor() as cursor:\n",
            "    command = \"SELECT distinct stay_id FROM mimiciv_derived.sepsis_patients_cohort ;\"\n",
            "    cursor.execute(command)   \n",
            "    result = cursor.fetchall()\n",
            "    stay_ids= [row[0] for row in result]\n",
            "    num_stay_ids = len(stay_ids)\n",
            "    print('Number of stay_ids: ' + str(num_stay_ids))\n",
            "    cursor.close()"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 3. Data transfor\n",
            "Here we first deal with the action data. \n",
            "TODO: here the value per minute is computed, do we need this? (paper4.1,P5)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 33,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "output action (IV_fluid_bolus):\tNaCl_0_9%.csv\n",
                  "output action (IV_fluid_bolus):\tDextrose_5%.csv\n",
                  "output action (vasopressors):\tNorepinephrine.csv\n",
                  "output action (vasopressors):\tVasopressin.csv\n",
                  "output action (vasopressors):\tDobutamine.csv\n",
                  "output action (vasopressors):\tMilrinone.csv\n",
                  "output action (vasopressors):\tPhenylephrine.csv\n",
                  "output action (vasopressors):\tDopamine.csv\n",
                  "output action (vasopressors):\tEpinephrine.csv\n"
               ]
            }
         ],
         "source": [
            "# generate the dictionary of action\n",
            "with open('csv/itemid_label_action.csv', newline='') as csvfile:\n",
            "    # Create a CSV reader object\n",
            "    reader = csv.reader(csvfile)\n",
            "    # Skip the header row\n",
            "    next(reader)\n",
            "    # Initialize an empty dictionary and list\n",
            "    action_label = {}\n",
            "    a_itemid_list = []\n",
            "    # Iterate over the rows in the CSV file\n",
            "    for row in reader:\n",
            "        # Add the key-value pair to the dictionary\n",
            "        action_label[row[0]] = row[1]\n",
            "        # Add the itemid to the list\n",
            "        a_itemid_list.append(row[0])\n",
            "\n",
            "if os.path.exists('./output/action/IV_fluid_bolus'):shutil.rmtree('./output/action/IV_fluid_bolus')\n",
            "if os.path.exists('./output/action/vasopressors'):shutil.rmtree('./output/action/vasopressors')\n",
            "os.makedirs('./output/action/IV_fluid_bolus')\n",
            "os.makedirs('./output/action/vasopressors')\n",
            "\n",
            "with conn.cursor() as cursor:\n",
            "\n",
            "    for itemid in a_itemid_list:\n",
            "        # QUESTION: why do we need to order by starttime?\n",
            "        command = \"select stay_id, starttime, endtime, amount from mimiciv_derived.sepsis_action where itemid={} order by starttime;\".format(itemid)\n",
            "        cursor.execute(command)\n",
            "\n",
            "        result = cursor.fetchall()\n",
            "        df = pd.DataFrame(result)\n",
            "        df.columns = ['stay_id', 'starttime', 'endtime', 'amount']\n",
            "        \n",
            "        df['duration'] = df['endtime'] - df['starttime']\n",
            "        df['duration'] = df['duration'].dt.total_seconds()  # Convert duration to seconds\n",
            "        df['duration'] = df['duration'] / 60\n",
            "        df['value_per_minute'] = df['amount'] / df['duration']\n",
            "        \n",
            "        if \"Dextrose_5%\" in action_label[str(itemid)] or \"NaCl_0_9%\" in action_label[str(itemid)]:\n",
            "            df.to_csv('./output/action/IV_fluid_bolus/{}.csv'.format(action_label[str(itemid)]), index=0)\n",
            "            print(\"output action (IV_fluid_bolus):\\t\"+action_label[str(itemid)]+\".csv\")\n",
            "        else:\n",
            "            df.to_csv('./output/action/vasopressors/{}.csv'.format(action_label[str(itemid)]), index=0)\n",
            "            print(\"output action (vasopressors):\\t\"+action_label[str(itemid)]+\".csv\")\n",
            "    cursor.close()\n",
            "    "
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### get IV fluid bolus statistical data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "项目\tIV fluid bolus\tCount\n",
                  "1\tDextrose_5%\t144445\n",
                  "2\tNaCl_0_9%\t183559\n"
               ]
            }
         ],
         "source": [
            "# 文件夹路径\n",
            "folder_path = 'output/action/IV_fluid_bolus'\n",
            "print('项目\\tIV fluid bolus\\tCount')\n",
            "\n",
            "# 获取文件夹中的所有CSV文件路径\n",
            "file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
            "\n",
            "index = 0\n",
            "# 遍历每个CSV文件，获取行数\n",
            "for file_path in file_paths:\n",
            "    file_name = os.path.basename(file_path)\n",
            "    with open(file_path, 'r', newline='') as csvfile:\n",
            "        csv_reader = csv.reader(csvfile)\n",
            "        rows = sum(1 for row in csv_reader)\n",
            "        index += 1\n",
            "    print(f\"{index}\\t{file_path[29:-4]}\\t{rows}\")\n"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### get Vasopressors statistical data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "项目\t血管加压药\tCount\t占比\t前n项占比\n",
                  "1\tNorepinephrine\t60081\t66.46%\t66.46%\n",
                  "2\tPhenylephrine\t19667\t21.76%\t88.22%\n",
                  "3\tVasopressin\t3763\t4.16%\t92.38%\n",
                  "4\tEpinephrine\t2829\t3.13%\t95.51%\n",
                  "5\tDopamine\t2448\t2.71%\t98.22%\n",
                  "6\tDobutamine\t1132\t1.25%\t99.47%\n",
                  "7\tMilrinone\t481\t0.53%\t100.0%\n",
                  "Total\t\t\t90401\t100%\t100%\n"
               ]
            }
         ],
         "source": [
            "# 文件夹路径\n",
            "folder_path = 'output/action/vasopressors'\n",
            "print('项目\\tVasopressors\\tCount\\t占比\\t前n项占比')\n",
            "\n",
            "# 获取文件夹中的所有CSV文件路径\n",
            "file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
            "\n",
            "# 存储每个CSV文件的行数\n",
            "rows_dict = {}\n",
            "\n",
            "# 计算行数之和\n",
            "total_rows = 0\n",
            "\n",
            "# 遍历每个CSV文件，获取行数\n",
            "for file_path in file_paths:\n",
            "    with open(file_path, 'r', newline='') as csvfile:\n",
            "        csv_reader = csv.reader(csvfile)\n",
            "        rows = sum(1 for row in csv_reader)\n",
            "        rows_dict[file_path] = rows\n",
            "        total_rows += rows\n",
            "\n",
            "# 按行数大小对字典进行排序\n",
            "sorted_rows = sorted(rows_dict.items(), key=lambda x: x[1], reverse=True)\n",
            "\n",
            "total_rows_first_n = 0\n",
            "index = 0\n",
            "# 打印排序结果\n",
            "for file_path, rows in sorted_rows:\n",
            "    index += 1\n",
            "    total_rows_first_n += rows\n",
            "    print(f\"{index}\\t{file_path[27:-4]}\\t{rows}\\t{round(rows/total_rows*100,2)}%\\t{round(total_rows_first_n/total_rows*100,2)}%\")\n",
            "print(f\"Total\\t\\t\\t{total_rows}\\t100%\\t100%\")"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "前5项血管加压药占比:98.22%，可见前5项血管加压药占比较大，因此我们只需要考虑前5项血管加压药即可。忽略Dobutamine和Milrinone。\n",
            "\n",
            "后两项血管加压药也被此文献忽视。'Vasopressor dose equivalence: A scoping review and suggested formula by Goradia et al. 2020'\n",
            "\n",
            "前5项血管加压药的等效计量值可以直接从mimiciv_derived.norepinephrine_equivalent_dose中获取:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "output action (vasopressors_norepinephrine_equivalent_dose.csv)\n",
                  "\n",
                  "项目\tVasopressors_norepinephrine_equivalent_dose\tCount\n",
                  "1\tvasopressors_norepinephrine_equivalent_dose\t91823\n"
               ]
            }
         ],
         "source": [
            "# 从mimiciv_derived.norepinephrine_equivalent_dose中获取前5项血管加压药的等效计量值 norepinephrine_equivalent_dose_rate\n",
            "\n",
            "with conn.cursor() as cursor:\n",
            "\n",
            "    command = \"select stay_id, starttime, endtime, norepinephrine_equivalent_dose from mimiciv_derived.norepinephrine_equivalent_dose where stay_id in (select stay_id from mimiciv_derived.sepsis_patients_cohort);\" # get norepinephrine_equivalent_dose_rate\n",
            "    cursor.execute(command)\n",
            "\n",
            "    result = cursor.fetchall()\n",
            "    df = pd.DataFrame(result)\n",
            "    df.columns = ['stay_id', 'starttime', 'endtime', 'norepinephrine_equivalent_dose_rate'] # norepinephrine_equivalent_dose in mcg/kg/min\n",
            "    \n",
            "    df['duration'] = df['endtime'] - df['starttime']\n",
            "    df['duration'] = df['duration'].dt.total_seconds()  # Convert duration to seconds\n",
            "    df['duration'] = df['duration'] / 60\n",
            "    df['norepinephrine_equivalent_dose_rate'] = df['norepinephrine_equivalent_dose_rate'].astype(float)\n",
            "    \n",
            "    df.to_csv('./output/action/vasopressors_norepinephrine_equivalent_dose.csv', index=0)\n",
            "    print(\"output action (vasopressors_norepinephrine_equivalent_dose.csv)\")\n",
            "\n",
            "    cursor.close()\n",
            "\n",
            "# 文件夹路径\n",
            "folder_path = 'output/action'\n",
            "print('\\n项目\\tVasopressors_norepinephrine_equivalent_dose\\tCount')\n",
            "\n",
            "# 获取文件夹中的所有CSV文件路径\n",
            "file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
            "\n",
            "index = 0\n",
            "# 遍历每个CSV文件，获取行数\n",
            "for file_path in file_paths:\n",
            "    file_name = os.path.basename(file_path)\n",
            "    with open(file_path, 'r', newline='') as csvfile:\n",
            "        csv_reader = csv.reader(csvfile)\n",
            "        rows = sum(1 for row in csv_reader)\n",
            "        index += 1\n",
            "    print(f\"{index}\\t{file_path[14:-4]}\\t{rows}\")"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Then, we treat the **state space** with similar method."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "output:Heartrate.csv                           \tnumber of stay_id:6669\n",
                  "output:ABPs.csv                                \tnumber of stay_id:2129\n",
                  "output:NBPs.csv                                \tnumber of stay_id:6632\n",
                  "output:ABPd.csv                                \tnumber of stay_id:2131\n",
                  "output:NBPd.csv                                \tnumber of stay_id:6632\n",
                  "output:ABPm.csv                                \tnumber of stay_id:2168\n",
                  "output:NBPm.csv                                \tnumber of stay_id:6632\n",
                  "output:RespiratoryRate.csv                     \tnumber of stay_id:6669\n",
                  "output:TemperatureF.csv                        \tnumber of stay_id:6576\n",
                  "output:TemperatureC.csv                        \tnumber of stay_id:832\n",
                  "output:PH_A.csv                                \tnumber of stay_id:3663\n",
                  "output:PH_V.csv                                \tnumber of stay_id:3184\n",
                  "output:ABE.csv                                 \tnumber of stay_id:3645\n",
                  "output:Hematocrit_serum.csv                    \tnumber of stay_id:6596\n",
                  "output:Hematocrit_wholeblood.csv               \tnumber of stay_id:1200\n",
                  "output:Hemoglobin.csv                          \tnumber of stay_id:6591\n",
                  "output:Platele.csv                             \tnumber of stay_id:6591\n",
                  "output:WBC.csv                                 \tnumber of stay_id:6593\n",
                  "output:Chloride_serum.csv                      \tnumber of stay_id:6618\n",
                  "output:Chloride_wholeblood.csv                 \tnumber of stay_id:1058\n",
                  "output:Calcium_ion.csv                         \tnumber of stay_id:3459\n",
                  "output:Calcium_nonion.csv                      \tnumber of stay_id:6549\n",
                  "output:Potassium_serum.csv                     \tnumber of stay_id:6617\n",
                  "output:Potassium_wholeblood.csv                \tnumber of stay_id:2181\n",
                  "output:Sodium_serum.csv                        \tnumber of stay_id:6617\n",
                  "output:Sodium_wholeblood.csv                   \tnumber of stay_id:1401\n",
                  "output:ProthrombinTime.csv                     \tnumber of stay_id:6011\n",
                  "output:PTT.csv                                 \tnumber of stay_id:5970\n",
                  "output:INR.csv                                 \tnumber of stay_id:6011\n",
                  "output:SaO2.csv                                \tnumber of stay_id:1905\n",
                  "output:SpO2.csv                                \tnumber of stay_id:6665\n",
                  "Error executing SQL statement: Length mismatch: Expected axis has 0 elements, new values have 3 elements\n",
                  "drop:PaO2.csv                                \tnumber of stay_id:0\n",
                  "output:PaCO2.csv                               \tnumber of stay_id:3645\n",
                  "output:FiO2.csv                                \tnumber of stay_id:4044\n",
                  "output:BUN.csv                                 \tnumber of stay_id:6616\n",
                  "output:Creatinine_serum.csv                    \tnumber of stay_id:6618\n",
                  "output:Creatinine_wholeblood.csv               \tnumber of stay_id:40\n",
                  "output:Albumin.csv                             \tnumber of stay_id:3608\n",
                  "output:AnionGap.csv                            \tnumber of stay_id:6617\n",
                  "output:TotalBilirubin.csv                      \tnumber of stay_id:4797\n",
                  "output:DirectBilirubin.csv                     \tnumber of stay_id:818\n",
                  "output:ALT.csv                                 \tnumber of stay_id:4771\n",
                  "output:AST.csv                                 \tnumber of stay_id:4769\n",
                  "drop:UrineOutput.csv                         \tnumber of stay_id:1\n",
                  "output:GCS_EyeOpening.csv                      \tnumber of stay_id:6669\n",
                  "output:GCS_VerbalResponse.csv                  \tnumber of stay_id:6668\n",
                  "output:GCS_MotorResponse.csv                   \tnumber of stay_id:6668\n",
                  "['220045', '220050', '220179', '220051', '220180', '220052', '220181', '220210', '223761', '223762', '223830', '220274', '224828', '220545', '226540', '220228', '227457', '220546', '220602', '226536', '225667', '225625', '227442', '227464', '220645', '226534', '227465', '227466', '227467', '220227', '220277', '220235', '223835', '225624', '220615', '229761', '227456', '227073', '225690', '225651', '220644', '220587', '220739', '223900', '223901']\n"
               ]
            }
         ],
         "source": [
            "threshold = 1000\n",
            "itemid_list_state=[]\n",
            "# generate the dictionary of itemid-abbr\n",
            "with open('csv/itemid_label_state.csv', newline='') as csvfile:\n",
            "    # Create a CSV reader object\n",
            "    reader = csv.reader(csvfile)\n",
            "    # Skip the header row\n",
            "    next(reader)\n",
            "    # Initialize an empty dictionary and list\n",
            "    label_state = {}\n",
            "    itemid_list = []\n",
            "    # Iterate over the rows in the CSV file\n",
            "    for row in reader:\n",
            "        # Add the key-value pair to the dictionary\n",
            "        label_state[row[0]] = row[1]\n",
            "        # Add the itemid to the list\n",
            "        itemid_list.append(row[0])\n",
            "\n",
            "# Execute the SQL command\n",
            "with conn.cursor() as cursor:\n",
            "    \n",
            "    for itemid in itemid_list:\n",
            "        \n",
            "        command_count = \"select count(distinct(stay_id)) from mimiciv_derived.sepsis_state where itemid={};\".format(itemid)\n",
            "        cursor.execute(command_count)\n",
            "        num = cursor.fetchone()[0]\n",
            "        \n",
            "        command = \"select stay_id, charttime, valuenum from mimiciv_derived.sepsis_state where itemid={} order by charttime;\".format(itemid)\n",
            "        cursor.execute(command)   \n",
            "        result = cursor.fetchall()\n",
            "        df=pd.DataFrame(result)\n",
            "        try:\n",
            "            df.columns = ['stay_id', 'charttime', 'valuenum']\n",
            "            df.astype({'stay_id': int, 'charttime': 'datetime64[ns]', 'valuenum': float})\n",
            "        except (Exception, psycopg2.DatabaseError) as error:\n",
            "            print(\"Error executing SQL statement:\", error) \n",
            "        os.makedirs('./output/state', exist_ok=True)\n",
            "        \n",
            "        if (num<num_stay_ids/threshold):\n",
            "            print(\"drop:{0:40}\".format(label_state[str(itemid)]+\".csv\")+\"\\tnumber of stay_id:\"+str(num))\n",
            "            \n",
            "        else:\n",
            "            df.to_csv('./output/state/{}.csv'.format(label_state[str(itemid)]),index=0)\n",
            "            itemid_list_state.append(itemid)\n",
            "            print(\"output:{0:40}\".format(label_state[str(itemid)]+\".csv\")+\"\\tnumber of stay_id:\"+str(num))\n",
            "        \n",
            "        \n",
            "        \n",
            "    cursor.close()\n",
            "print(itemid_list_state)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 4.hourly sample"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "def hourly_resample(selected_id):\n",
            "    # Set the folder path where the CSV files are stored\n",
            "    folder_path = './output/state/'\n",
            "    columns=['chartdatetime']\n",
            "\n",
            "    # define a new dataframe\n",
            "    df_output = pd.DataFrame(columns=columns)\n",
            "\n",
            "    # selected_id = 32768012\n",
            "    #selected_id = 32950566\n",
            "\n",
            "    #FIXME: flag only for test\n",
            "    i=0\n",
            "\n",
            "    # Loop through the file paths and read each file into a DataFrame\n",
            "    for itemid in itemid_list_state:\n",
            "        \n",
            "        feature=label_state[str(itemid)]\n",
            "        path = folder_path + feature+'.csv'\n",
            "        \n",
            "        # Load the CSV file into a pandas DataFrame\n",
            "        dtypes={'stay_id':str,'chartdatetime':str,feature:str}\n",
            "        df = pd.read_csv(path,names=['stay_id', 'chartdatetime', feature ],dtype=dtypes)\n",
            "        df['stay_id'] = pd.to_numeric(df['stay_id'], errors='coerce')\n",
            "        \n",
            "        # Filter the DataFrame to only the rows from the selected stay_id\n",
            "        df_filtered = df[df['stay_id'] == selected_id]\n",
            "        \n",
            "        # Convert the 'datetime' column to a datetime object\n",
            "        df_filtered.loc[:,'chartdatetime'] = pd.to_datetime(df_filtered['chartdatetime'].copy())\n",
            "        #df_filtered['chartdatetime'] = df_filtered['chartdatetime'].apply(pd.to_datetime)\n",
            "\n",
            "        # Set the 'datetime' column as the DataFrame's index\n",
            "        df_filtered.set_index('chartdatetime', inplace=True)\n",
            "        \n",
            "        # # Resample the DataFrame hourly and forward fill missing values\n",
            "        df_hourly= df_filtered.resample('H').ffill()\n",
            "        df_hourly=df_hourly.drop(['stay_id'],axis=1)\n",
            "        \n",
            "        df_output['chartdatetime'] = pd.to_datetime(df_output['chartdatetime'])\n",
            "        #df_output = pd.concat([df_output, df_hourly], join=\"outer\",sort=False)\n",
            "        df_output=pd.merge(df_output,df_hourly,how='outer',on='chartdatetime')\n",
            "\n",
            "        \n",
            "        i+=1\n",
            "        if(i==50): break\n",
            "\n",
            "    os.makedirs('./output/hourly_sample/', exist_ok=True)\n",
            "    df_output.reset_index().to_csv(f'./output/hourly_sample/stay_id{selected_id}.csv',index=0)\n",
            "\n",
            "    # print(i)\n",
            "\n",
            "    # # Reset the index and save the resampled DataFrame to a new CSV file\n",
            "    # df_hourly.reset_index().to_csv('./output/your_resampled_file.csv', index=False, header=None)  "
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Loop hourly_resample through stay_ids"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "for selected_id in stay_ids:\n",
            "    hourly_resample(selected_id)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "MLhomework",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.11"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
