{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIMIC_Sepsis\n",
    "=================\n",
    "\n",
    "# 1 Preparation\n",
    "\n",
    "To run this document the following requirements must be satisfied:\n",
    "\n",
    "- Implement the database mimic in **PostgreSQL** and start it. The instruction can be seen [here](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iv/buildmimic/postgres). (The name of this environment should be **mimiciv**)\n",
    "- generate useful abstractions of raw MIMIC-IV data. The instruction be seen [here](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iv/concepts_postgres) \n",
    "\n",
    "\n",
    "\n",
    "To create an anaconda environment and install all the required libraries, uncomment following and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda create --name mimiciv_sepsis python=3.11\n",
    "#!conda activate mimiciv_sepsis\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to connect to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "from datetime import timedelta\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# implement the username, password and database name\n",
    "conn = psycopg2.connect(host='', user='', password='', database='mimiciv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Extract selected data from the original database \n",
    "\n",
    "We extract the `state space` and `action space` respectively from the mimiciv database. The table `itemid_info/mimic4 itemid.csv` lists all the items required.\n",
    "\n",
    "***Uncomment the following cell if you first time run the code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mimiciv_derived_sepsis.sepsis_patients_cohort is created\n",
      "mimiciv_derived_sepsis.sepsis_state is created\n",
      "mimiciv_derived_sepsis.sepsis_action_inputevents is created\n",
      "mimiciv_derived_sepsis.sepsis_action_vasopressors_equivalent_dose is created\n"
     ]
    }
   ],
   "source": [
    "# uncomment the this cell if you first time run the code\n",
    "\n",
    "# Read the SQL file\n",
    "\n",
    "try:\n",
    "    with open('sql/select_patients_cohort.sql', 'r') as file0:\n",
    "        sql_script_select_patients_cohort = file0.read()\n",
    "        \n",
    "    with open('sql/state_from_chartevents.sql', 'r') as file1:\n",
    "        sql_script_state = file1.read()\n",
    "\n",
    "    with open('sql/action_from_inputevents.sql', 'r') as file2:\n",
    "        sql_script_action_from_inputevents = file2.read()\n",
    "\n",
    "    with open('sql/action_from_vasopressors_equivalent_dose.sql', 'r') as file3:\n",
    "        sql_script_action_from_vasopressors_equivalent_dose = file3.read()\n",
    "\n",
    "    # Execute the SQL script and create the tables in schema mimiciv_derived_sepsis\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(sql.SQL(sql_script_select_patients_cohort))\n",
    "    print(\"mimiciv_derived_sepsis.sepsis_patients_cohort is created\")\n",
    "\n",
    "    cursor.execute(sql.SQL(sql_script_state))\n",
    "    print(\"mimiciv_derived_sepsis.sepsis_state is created\")\n",
    "\n",
    "    cursor.execute(sql.SQL(sql_script_action_from_inputevents))\n",
    "    print(\"mimiciv_derived_sepsis.sepsis_action_inputevents is created\")\n",
    "\n",
    "    cursor.execute(sql.SQL(sql_script_action_from_vasopressors_equivalent_dose))\n",
    "    print(\"mimiciv_derived_sepsis.sepsis_action_vasopressors_equivalent_dose is created\")\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    \n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(\"Error executing SQL statement:\", error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of stay_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stay_ids: 7404\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    command = \"SELECT distinct stay_id FROM mimiciv_derived_sepsis.sepsis_patients_cohort;\"\n",
    "    cursor.execute(command)   \n",
    "    result = cursor.fetchall()\n",
    "    stay_ids= [row[0] for row in result]\n",
    "    num_stay_ids = len(stay_ids)\n",
    "    print('Number of stay_ids: ' + str(num_stay_ids))\n",
    "    cursor.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data transfer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data transfer of State Space\n",
    "We transfer the data of State Space from Postgresql to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    command = \"SELECT icu.stay_id, a.age, pat.gender, pat.dod FROM mimiciv_derived.age as a  INNER JOIN mimiciv_hosp.patients pat  ON a.subject_id = pat.subject_id INNER JOIN mimiciv_icu.icustays icu ON icu.subject_id = a.subject_id and icu.hadm_id=a.hadm_id INNER JOIN mimiciv_derived_sepsis.sepsis_patients_cohort sepsis ON sepsis.stay_id=icu.stay_id;\"\n",
    "    cursor.execute(command)   \n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "df=pd.DataFrame(result)\n",
    "df.columns = ['stay_id', 'age', 'gender', 'dod']\n",
    "\n",
    "#binary\n",
    "df['dod_b']=df['dod'].apply(lambda x: 1 if x is not None else 0)\n",
    "\n",
    "# normailzation\n",
    "df['gender_n']=df['gender'].apply(lambda x: 1 if x=='M' else 0) \n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_n']=(df['age']-df['age'].mean())/(df['age'].std())\n",
    "\n",
    "minimum = min(df['age_n'])\n",
    "maximum = max(df['age_n'])\n",
    "df['age_n'] = (df['age_n'] - minimum)/(maximum-minimum)\n",
    "\n",
    "\n",
    "df.to_csv('./output/data/data_raw/PatientAttribute.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of value is: 48\n",
      "output:Heartrate.csv                           \tpercent of stay_id:1.0\n",
      "output:ABPs.csv                                \tpercent of stay_id:0.297947055645597\n",
      "output:NBPs.csv                                \tpercent of stay_id:0.9777147487844409\n",
      "output:ABPd.csv                                \tpercent of stay_id:0.29808211777417615\n",
      "output:NBPd.csv                                \tpercent of stay_id:0.9775796866558617\n",
      "output:ABPm.csv                                \tpercent of stay_id:0.3024041058887088\n",
      "output:NBPm.csv                                \tpercent of stay_id:0.9775796866558617\n",
      "output:RespiratoryRate.csv                     \tpercent of stay_id:0.9998649378714208\n",
      "output:TemperatureF.csv                        \tpercent of stay_id:0.9706915180983252\n",
      "output:TemperatureC.csv                        \tpercent of stay_id:0.09805510534846029\n",
      "output:PH_A.csv                                \tpercent of stay_id:0.531334413830362\n",
      "output:PH_V.csv                                \tpercent of stay_id:0.4211237169097785\n",
      "output:ABE.csv                                 \tpercent of stay_id:0.5287682333873582\n",
      "output:Hematocrit_serum.csv                    \tpercent of stay_id:0.9901404646137223\n",
      "drop:Hematocrit_wholeblood.csv               \tnumber of stay_id:1124\n",
      "output:Hemoglobin.csv                          \tpercent of stay_id:0.9893300918422474\n",
      "output:Platele.csv                             \tpercent of stay_id:0.9891950297136682\n",
      "output:WBC.csv                                 \tpercent of stay_id:0.9896002160994057\n",
      "output:Chloride_serum.csv                      \tpercent of stay_id:0.9931118314424635\n",
      "drop:Chloride_wholeblood.csv                 \tnumber of stay_id:952\n",
      "output:Calcium_ion.csv                         \tpercent of stay_id:0.4863587250135062\n",
      "output:Calcium_nonion.csv                      \tpercent of stay_id:0.9800108049702864\n",
      "output:Potassium_serum.csv                     \tpercent of stay_id:0.9931118314424635\n",
      "output:Potassium_wholeblood.csv                \tpercent of stay_id:0.2747163695299838\n",
      "output:Sodium_serum.csv                        \tpercent of stay_id:0.9929767693138843\n",
      "drop:Sodium_wholeblood.csv                   \tnumber of stay_id:1247\n",
      "output:ProthrombinTime.csv                     \tpercent of stay_id:0.8876283090221502\n",
      "output:PTT.csv                                 \tpercent of stay_id:0.8803349540788763\n",
      "output:INR.csv                                 \tpercent of stay_id:0.8876283090221502\n",
      "output:SaO2.csv                                \tpercent of stay_id:0.23325229605618583\n",
      "output:SpO2.csv                                \tpercent of stay_id:0.9994597514856834\n",
      "Error executing SQL statement: Length mismatch: Expected axis has 0 elements, new values have 3 elements\n",
      "drop:PaO2.csv                                \tnumber of stay_id:0\n",
      "output:PaCO2.csv                               \tpercent of stay_id:0.5287682333873582\n",
      "output:FiO2.csv                                \tpercent of stay_id:0.5990005402485143\n",
      "output:BUN.csv                                 \tpercent of stay_id:0.9929767693138843\n",
      "output:Creatinine_serum.csv                    \tpercent of stay_id:0.9931118314424635\n",
      "drop:Creatinine_wholeblood.csv               \tnumber of stay_id:33\n",
      "output:Albumin.csv                             \tpercent of stay_id:0.4647487844408428\n",
      "output:AnionGap.csv                            \tpercent of stay_id:0.9929767693138843\n",
      "output:TotalBilirubin.csv                      \tpercent of stay_id:0.678011885467315\n",
      "drop:DirectBilirubin.csv                     \tnumber of stay_id:632\n",
      "output:ALT.csv                                 \tpercent of stay_id:0.6750405186385737\n",
      "output:AST.csv                                 \tpercent of stay_id:0.6747703943814155\n",
      "drop:UrineOutput.csv                         \tnumber of stay_id:1\n",
      "output:GCS_EyeOpening.csv                      \tpercent of stay_id:0.9998649378714208\n",
      "output:GCS_VerbalResponse.csv                  \tpercent of stay_id:0.9997298757428417\n",
      "output:GCS_MotorResponse.csv                   \tpercent of stay_id:0.9997298757428417\n",
      "output:daily_weight.csv                        \tpercent of stay_id:0.401269584008644\n",
      "the number remain is: 41\n"
     ]
    }
   ],
   "source": [
    "# output to /output/data/data_raw/state/{state_name}.csv\n",
    "from python.data_preprocessing.data_transfer import data_transfer_state\n",
    "\n",
    "itemid_list_state, label_state = data_transfer_state(conn, num_stay_ids, percent=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data transfer of Action Space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Data transfer of Action Space for *IV fluid bolus*\n",
    "\n",
    " - IV fluid bolus\n",
    "   - NaCl_0.9%\n",
    "   - Dextrose_5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output action (IV_fluid_bolus):\tNaCl_0_9%.csv\n",
      "output action (IV_fluid_bolus):\tDextrose_5%.csv\n"
     ]
    }
   ],
   "source": [
    "# output to /output/data/data_raw/action/IV_fluid_bolus/{IV_fluid_bolus_name}.csv\n",
    "from python.data_preprocessing.data_transfer import data_transfer_action_IV_fluid_bolus\n",
    "\n",
    "data_transfer_action_IV_fluid_bolus(conn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Data transfer of Action Space for *Vasopressors*\n",
    "\n",
    "we directly obtain `vasopressors_equivalent_dose` \n",
    "\n",
    "from `mimiciv_derived.norepinephrine_equivalent_dose` \n",
    "\n",
    "based on *\"Vasopressor dose equivalence: A scoping review and suggested formula\" by Goradia et al. 2020*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output action (vasopressors): vasopressors_equivalent_dose.csv\n"
     ]
    }
   ],
   "source": [
    "# output to /output/data/data_raw/action/vasopressors/vasopressors_equivalent_dose.csv\n",
    "from python.data_preprocessing.data_transfer import data_transfer_action_vasopressors_equivalent_dose\n",
    "\n",
    "data_transfer_action_vasopressors_equivalent_dose(conn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Data Summerization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Hourly Sample on State Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7404 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'itemid_list_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/han/anaconda3/envs/mimiciv_sepsis/lib/python3.11/concurrent/futures/process.py\", line 256, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/han/anaconda3/envs/mimiciv_sepsis/lib/python3.11/concurrent/futures/process.py\", line 205, in _process_chunk\n    return [fn(*args) for args in chunk]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/han/anaconda3/envs/mimiciv_sepsis/lib/python3.11/concurrent/futures/process.py\", line 205, in <listcomp>\n    return [fn(*args) for args in chunk]\n            ^^^^^^^^^\n  File \"/tmp/ipykernel_128797/1258082160.py\", line 26, in process_id\n    return hourly_sample_state(df_state_space, selected_id, itemid_list_state, label_state, k=10)\n                                                            ^^^^^^^^^^^^^^^^^\nNameError: name 'itemid_list_state' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/han/Documents/TUM/MIMIC-IV/mimic4_sepsis/01_data_preprocessing.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/han/Documents/TUM/MIMIC-IV/mimic4_sepsis/01_data_preprocessing.ipynb#Y111sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_id\u001b[39m(selected_id):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/han/Documents/TUM/MIMIC-IV/mimic4_sepsis/01_data_preprocessing.ipynb#Y111sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m hourly_sample_state(df_state_space, selected_id, itemid_list_state, label_state, k\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/han/Documents/TUM/MIMIC-IV/mimic4_sepsis/01_data_preprocessing.ipynb#Y111sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m results \u001b[39m=\u001b[39m process_map(process_id, selected_ids, max_workers\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, chunksize\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m) \u001b[39m# Set max_workers to the number of cores you want to use\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/han/Documents/TUM/MIMIC-IV/mimic4_sepsis/01_data_preprocessing.ipynb#Y111sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m df_state_space \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(results)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/han/Documents/TUM/MIMIC-IV/mimic4_sepsis/01_data_preprocessing.ipynb#Y111sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m df_state_space\u001b[39m.\u001b[39mreset_index()\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./output/data/data_hourly_sample/state/df_state_space.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mimiciv_sepsis/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:105\u001b[0m, in \u001b[0;36mprocess_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     tqdm_kwargs \u001b[39m=\u001b[39m tqdm_kwargs\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    104\u001b[0m     tqdm_kwargs[\u001b[39m\"\u001b[39m\u001b[39mlock_name\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmp_lock\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m _executor_map(ProcessPoolExecutor, fn, \u001b[39m*\u001b[39;49miterables, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtqdm_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/mimiciv_sepsis/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name\u001b[39m=\u001b[39mlock_name) \u001b[39mas\u001b[39;00m lk:\n\u001b[1;32m     48\u001b[0m     \u001b[39m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[39mwith\u001b[39;00m PoolExecutor(max_workers\u001b[39m=\u001b[39mmax_workers, initializer\u001b[39m=\u001b[39mtqdm_class\u001b[39m.\u001b[39mset_lock,\n\u001b[1;32m     50\u001b[0m                       initargs\u001b[39m=\u001b[39m(lk,)) \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m---> 51\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(tqdm_class(ex\u001b[39m.\u001b[39;49mmap(fn, \u001b[39m*\u001b[39;49miterables, chunksize\u001b[39m=\u001b[39;49mchunksize), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/anaconda3/envs/mimiciv_sepsis/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mimiciv_sepsis/lib/python3.11/concurrent/futures/process.py:606\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    601\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[39m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[39m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[39m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m    607\u001b[0m         element\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    608\u001b[0m         \u001b[39mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m~/anaconda3/envs/mimiciv_sepsis/lib/python3.11/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39;49mpop())\n\u001b[1;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/anaconda3/envs/mimiciv_sepsis/lib/python3.11/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult(timeout)\n\u001b[1;32m    318\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/anaconda3/envs/mimiciv_sepsis/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/mimiciv_sepsis/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'itemid_list_state' is not defined"
     ]
    }
   ],
   "source": [
    "# output to /output/data/data_hourly_sample/state/stay_id_{selected_id}.csv\n",
    "from python.data_preprocessing.hourly_sample import hourly_sample_state\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from multiprocessing import Pool\n",
    "\n",
    "if os.path.exists('./output/data/data_hourly_sample/state'):shutil.rmtree('./output/data/data_hourly_sample/state')\n",
    "os.makedirs('./output/data/data_hourly_sample/state', exist_ok=True)\n",
    "\n",
    "df_state_space = pd.DataFrame()\n",
    "\n",
    "# FIXME: code for test\n",
    "# selected_ids = random.sample(stay_ids, 100)\n",
    "selected_ids = stay_ids\n",
    "# print(f'Selected stay_id: {selected_ids}')\n",
    "# selected_id = 31872514\n",
    "\n",
    "# for selected_id in tqdm(selected_ids):\n",
    "#     df_state_space=hourly_sample_state(df_state_space,selected_id, itemid_list_state, label_state, k = 10)\n",
    "    \n",
    "# df_state_space.reset_index().to_csv(f'./output/data/data_hourly_sample/state/df_state_space.csv')\n",
    "\n",
    "def process_id(selected_id):\n",
    "    return hourly_sample_state(df_state_space, selected_id, itemid_list_state, label_state, k=10)\n",
    "\n",
    "results = process_map(process_id, selected_ids, max_workers=8, chunksize=10) # Set max_workers to the number of cores you want to use\n",
    "\n",
    "df_state_space = pd.concat(results)\n",
    "df_state_space.reset_index().to_csv(f'./output/data/data_hourly_sample/state/df_state_space.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2 combination\n",
    "combine the data with age, gender, survival situation in patient attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_patient_attribute = pd.read_csv('./output/data/data_raw/PatientAttribute.csv', header=0)\n",
    "df_patient_attribute = df_patient_attribute.drop(0)\n",
    "\n",
    "# remove columns 'dod', 'gender', 'age'\n",
    "df_patient_attribute = df_patient_attribute.drop(['dod', 'gender', 'age'], axis=1)\n",
    "\n",
    "\n",
    "df_state_space_f = pd.merge(df_patient_attribute, df_state_space, on='stay_id', how='right')\n",
    "df_state_space_f.to_csv('./output/data/data_hourly_sample/state/df_state_space_f.csv', index=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3 state cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cluster_num = 1250\n",
    "\n",
    "features = [label_state[itemid] for itemid in itemid_list_state] +['gender_n','age_n']\n",
    "features.remove('TemperatureC')\n",
    "\n",
    "# Convert your DataFrame to a matrix\n",
    "matrix = df_state_space_f[features].fillna(0).values\n",
    "\n",
    "# Apply NMF\n",
    "model = NMF(n_components=cluster_num, init='random', random_state=0)\n",
    "W = model.fit_transform(matrix)\n",
    "H = model.components_\n",
    "# print(H.shape)\n",
    "kmeans_train = KMeans(n_clusters=cluster_num, random_state=0, verbose=True, n_init=5).fit(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 assemble all the data related to state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_clusters = kmeans_train.labels_\n",
    "state_set_final = pd.DataFrame()\n",
    "state_set_final['stay_id']=df_state_space_f['stay_id']\n",
    "state_set_final['chartdatetime']=df_state_space_f['chartdatetime']\n",
    "state_set_final['state']=state_clusters\n",
    "state_set_final['mortality']=df_state_space_f['dod_b']\n",
    "\n",
    "#FIXME: still missing: reward ,action\n",
    "\n",
    "state_set_final.to_csv('./output/data/data_hourly_sample/state/df_state_space_final.csv', index=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Hourly Sample on Action Space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Hourly sample IV_fluid_bolus for both continuous and discrete action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7404/7404 [04:47<00:00, 25.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error count: 0\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "# output to /output/data/data_hourly_sample/action/IV_fluid_bolus/stay_id_{selected_id}.csv\n",
    "from python.data_preprocessing.hourly_sample import hourly_sample_action_IV_fluid_bolus\n",
    "if os.path.exists('./output/data/data_hourly_sample/action/IV_fluid_bolus/'):shutil.rmtree('./output/data/data_hourly_sample/action/IV_fluid_bolus/')\n",
    "\n",
    "\n",
    "# selected_id = 31872514 # more than 72 hours ICU stay \n",
    "# print(f'Selected stay_id: {selected_id}')\n",
    "# hourly_sample_action_IV_fluid_bolus(selected_id)\n",
    "\n",
    "# count = 0\n",
    "# for selected_id in stay_ids:\n",
    "#     try:\n",
    "#         hourly_sample_action_IV_fluid_bolus(selected_id)\n",
    "#     except:\n",
    "#         # print(f'Error with {selected_id}')\n",
    "#         count += 1\n",
    "# print(f'Error count: {count}') # 911 out of 7404 stay_ids (12.3%) did not have IV_fluid_bolus. 7404 - 911 = 6493 (87.7%) stay_ids have IV_fluid_bolus\n",
    "\n",
    "def process_id(selected_id):\n",
    "    try:\n",
    "        return hourly_sample_action_IV_fluid_bolus(selected_id)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "results = process_map(process_id, stay_ids, max_workers=8, chunksize=10) # Set max_workers to the number of cores you want to use\n",
    "\n",
    "results = [r for r in results if r is not None]\n",
    "\n",
    "df_action_space_IV_fluid_bolus = pd.concat(results)\n",
    "df_action_space_IV_fluid_bolus.to_csv(f'./output/data/data_hourly_sample/action/df_action_space_IV_fluid_bolus.csv', index=False)\n",
    "\n",
    "count = sum(1 for result in results if result is None)\n",
    "print(f'Error count: {count}') # TODO 911 out of 7404 stay_ids (12.3%) did not have IV_fluid_bolus. 7404 - 911 = 6493 (87.7%) stay_ids have IV_fluid_bolus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Hourly sample vasopressors_equivalent_dose for both continuous and discrete action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7404/7404 [01:20<00:00, 92.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error count: 0\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "# output to /output/data/data_hourly_sample/action/vasopressors_equivalent_dose/stay_id_{selected_id}.csv\n",
    "from python.data_preprocessing.hourly_sample import hourly_sample_action_vasopressors_equivalent_dose\n",
    "if os.path.exists('./output/data/data_hourly_sample/action/vasopressors_equivalent_dose'):shutil.rmtree('./output/data/data_hourly_sample/action/vasopressors_equivalent_dose')\n",
    "\n",
    "\n",
    "# selected_id = 31872514 # more than 72 hours ICU stay \n",
    "# print(f'Selected stay_id: {selected_id}')\n",
    "# hourly_sample_action_vasopressors_equivalent_dose(selected_id)\n",
    "\n",
    "# count = 0\n",
    "# for selected_id in stay_ids:\n",
    "#     try:\n",
    "#         hourly_sample_action_vasopressors_equivalent_dose(selected_id)\n",
    "#     except:\n",
    "#         # print(f'Error with {selected_id}')\n",
    "#         count += 1\n",
    "# print(f'Error count: {count}') # 4452 out of 7404 stay_ids (60.1%) did not have vasopressors. 7404 - 4452 = 2952 (39.9%) stay_ids have vasopressors\n",
    "\n",
    "def process_id(selected_id):\n",
    "    try:\n",
    "        return hourly_sample_action_vasopressors_equivalent_dose(selected_id)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "results = process_map(process_id, stay_ids, max_workers=8, chunksize=10) # Set max_workers to the number of cores you want to use\n",
    "\n",
    "results = [r for r in results if r is not None]\n",
    "\n",
    "df_action_space_vasopressors_equivalent_dose = pd.concat(results)\n",
    "df_action_space_vasopressors_equivalent_dose.to_csv(f'./output/data/data_hourly_sample/action/df_action_space_vasopressors_equivalent_dose.csv', index=False)\n",
    "\n",
    "count = sum(1 for result in results if result is None)\n",
    "print(f'Error count: {count}') # TODO 4452 out of 7404 stay_ids (60.1%) did not have vasopressors. 7404 - 4452 = 2952 (39.9%) stay_ids have vasopressors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
